{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b9801b-dfbb-43c0-a80e-58d7b4db099e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "\n",
    "src = r\"C:\\Users\\user\\Desktop\\Coding mo\\AutoML proj1\\task 1\\AutoML Project Molham\\src\" # copy the location of the folder that has paths.py file using (ctrl + shift + C ) and paste it here    \n",
    "sys.path.append(src)\n",
    "\n",
    "from paths import *\n",
    "\n",
    "get_paths()\n",
    "\n",
    "sys.path.append(SRC_PATH)\n",
    "\n",
    "from pipeline import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775abf10-e183-4374-8b68-515b6b101e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(ABLATION_MODELS_FOR_SHAP_PATH, \"all_results.pkl\"), \"rb\") as f:\n",
    "    all_results = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(ABLATION_MODELS_FOR_SHAP_PATH, \"best_models_dict.pkl\"), \"rb\") as f:\n",
    "    best_models_dict = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(ABLATION_MODELS_FOR_SHAP_PATH, \"X_dict.pkl\"), \"rb\") as f:\n",
    "    X_dict = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(ABLATION_MODELS_FOR_SHAP_PATH, \"feature_names_dict.pkl\"), \"rb\") as f:\n",
    "    feature_names_dict = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24b58f5-54a1-4d76-b3df-e9639b46f749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependency package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependency package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependency package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependency package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependency package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependency package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 20001it [1:25:22,  3.90it/s]                           \n",
      "PermutationExplainer explainer: 20001it [1:26:20,  3.85it/s]                           \n",
      "PermutationExplainer explainer: 90it [01:38,  1.23s/it]                        \n",
      "PermutationExplainer explainer: 90it [01:45,  1.30s/it]                        \n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "def run_simple_explainability(all_results, best_models_dict, X_dict, feature_names_dict, max_rows=500, \n",
    "                              top_features_count=3, force_samples_count=2):\n",
    "\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "\n",
    "    for dataset_name in df_results['dataset'].unique():\n",
    "        for fold in df_results[df_results['dataset']==dataset_name]['fold'].unique():\n",
    "\n",
    "\n",
    "            def predict_fn(X_np):\n",
    "                X_df = pd.DataFrame(X_np, columns=X_sample.columns)\n",
    "                return model.predict(X_df).data[:, 0]\n",
    "\n",
    "\n",
    "            \n",
    "            fold_df = df_results[(df_results['dataset']==dataset_name) & (df_results['fold']==fold)]\n",
    "            best_row = fold_df.loc[fold_df['f1'].idxmax()]\n",
    "            best_ablation = best_row['ablation']\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            model_path = best_models_dict[dataset_name][f\"fold_{fold}\"][best_ablation]\n",
    "            with open(model_path, \"rb\") as f:\n",
    "                model = pickle.load(f)\n",
    "\n",
    "\n",
    "            \n",
    "            X_val = X_dict[dataset_name][f\"fold_{fold}\"].copy()\n",
    "            feature_names_after = feature_names_dict[dataset_name][f\"fold_{fold}\"][best_ablation][\"after\"]\n",
    "            if X_val.shape[1] != len(feature_names_after):\n",
    "                feature_names_after = [f\"f_{i}\" for i in range(X_val.shape[1])]\n",
    "            X_val.columns = feature_names_after\n",
    "\n",
    "            \n",
    "            X_sample = X_val.sample(n=min(max_rows, X_val.shape[0]), random_state=42)\n",
    "            X_sample_np = X_sample.to_numpy()\n",
    "\n",
    "            \n",
    "            model_name = f\"{dataset_name}_fold{fold}_{best_ablation}\"\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            try:\n",
    "                background = X_sample_np[:min(100, X_sample_np.shape[0]), :]\n",
    "                explainer = shap.Explainer(predict_fn, background)\n",
    "                shap_values = explainer(X_sample_np)\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            try:\n",
    "                summary_path = os.path.join(FEATURE_IMPORTANCE_SHAP_PATH, f\"{model_name}_summary.png\")\n",
    "                shap.summary_plot(shap_values.values, X_sample, feature_names=X_sample.columns, show=False)\n",
    "                plt.savefig(summary_path, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            try:\n",
    "                bar_path = os.path.join(FEATURE_IMPORTANCE_SHAP_PATH, f\"{model_name}_importance.png\")\n",
    "                shap.summary_plot(shap_values.values, X_sample, feature_names=X_sample.columns, plot_type=\"bar\", show=False)\n",
    "                plt.savefig(bar_path, bbox_inches=\"tight\")\n",
    "                plt.close()\n",
    "\n",
    "            \n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            top_features = X_sample.columns[:min(top_features_count, X_sample.shape[1])]\n",
    "\n",
    "\n",
    "            \n",
    "            for f in top_features:\n",
    "                try:\n",
    "                    dep_path = os.path.join(PER_FEATURE_SHAP_PATH, f\"{model_name}_dependence_{f}.png\")\n",
    "                    shap.dependence_plot(f, shap_values.values, X_sample, show=False)\n",
    "                    plt.savefig(dep_path, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            for i in range(min(force_samples_count, X_sample.shape[0])):\n",
    "\n",
    "                try:\n",
    "                    sample = X_sample.iloc[i, :]\n",
    "                    sample_explainer = shap.Explainer(predict_fn, X_sample_np[:min(100, X_sample_np.shape[0]), :])\n",
    "                    sample_shap = sample_explainer(sample.to_frame().T)\n",
    "\n",
    "                    force_path = os.path.join(SAMPLES_SHAP_PATH, f\"{model_name}_force_{i}.png\")\n",
    "                    shap.plots.force(sample_shap, matplotlib=True, show=False)\n",
    "                    plt.savefig(force_path, bbox_inches=\"tight\")\n",
    "                    plt.close()\n",
    "\n",
    "                \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "run_simple_explainability(all_results=all_results, best_models_dict=best_models_dict, X_dict=X_dict, feature_names_dict=feature_names_dict, max_rows=20000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f41ac-c4f0-4d37-bd73-bb72c644d9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (exxx)",
   "language": "python",
   "name": "exxx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
